{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fed_Learning_LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxmewjDBu7E-",
        "outputId": "65c52c90-a00c-4fe2-c3d0-fe7f32878104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import time\n",
        "import pickle\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "# from tensorflow.keras.regularizers import  l1,l2\n",
        "from collections import Counter\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "yoLVlIJxv5NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_vector_embedding=20\n",
        "voc_size=30000\n",
        "sentence_length=20"
      ],
      "metadata": {
        "id": "hhBSTdCI0bs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Client:\n",
        "    feature_vector_embedding=20\n",
        "    voc_size=30000\n",
        "    sentence_length=20\n",
        "\n",
        "    \n",
        "    def __init__(self, dataset_x, dataset_y, epoch_number, learning_rate,weights,batch,x_valid,y_valid):\n",
        "        self.dataset_x=dataset_x\n",
        "        self.dataset_y=dataset_y\n",
        "        self.epoch_number=epoch_number\n",
        "        self.learning_rate=learning_rate\n",
        "        self.weights=weights\n",
        "        self.batch=batch\n",
        "        self.x_valid=x_valid\n",
        "        self.y_valid=y_valid\n",
        "        \n",
        "        \n",
        "    def train(self): \n",
        "        import numpy as np\n",
        "        # import pandas as pd\n",
        "        import matplotlib as plt\n",
        "        from tensorflow import keras\n",
        "        \n",
        "        model = keras.models.Sequential([\n",
        "        keras.layers.Embedding(voc_size,feature_vector_embedding, input_length=sentence_length),\n",
        "        keras.layers.GRU(30, return_sequences=True),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.GRU(20, return_sequences=True),\n",
        "        keras.layers.GRU(10, return_sequences=True),\n",
        "        keras.layers.GRU(5),\n",
        "        keras.layers.Dense(3, activation=\"softmax\")\n",
        "    ])\n",
        "        \n",
        "        #setting weight of the model\n",
        "        model.set_weights(self.weights)\n",
        "        \n",
        "        model.compile(loss='sparse_categorical_crossentropy',optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "        history=model.fit(self.dataset_x, self.dataset_y, validation_data=(self.x_valid, self.y_valid), epochs=self.epoch_number, batch_size=self.batch)        \n",
        "       \n",
        "        #getting the final_weight\n",
        "        output_weight=model.get_weights()        \n",
        "        return output_weight"
      ],
      "metadata": {
        "id": "WGn7mt9VwBBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redo"
      ],
      "metadata": {
        "id": "9-5Kvoffp5hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"/content/drive/MyDrive/Datasets/x_train\",'rb')\n",
        "x_train= pickle.load(file)\n",
        "x_train=x_train[:75000,:]\n",
        "\n",
        "file = open(\"/content/drive/MyDrive/Datasets/y_train\",'rb')\n",
        "y_train= pickle.load(file)\n",
        "y_train=y_train[:75000]\n",
        "\n",
        "file = open(\"/content/drive/MyDrive/Datasets/x_test\",'rb')\n",
        "x_test= pickle.load(file)\n",
        "x_test=x_test[:25000,:]\n",
        "\n",
        "file = open(\"/content/drive/MyDrive/Datasets/y_test\",'rb')\n",
        "y_test= pickle.load(file)\n",
        "y_test=y_test[:25000]\n",
        "\n"
      ],
      "metadata": {
        "id": "xRCBJhgcwFLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(x_train))\n",
        "print(type(y_train))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyorhUc92A5X",
        "outputId": "76ae3e4f-f61b-4046-c137-f9df079620de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(75000, 20)\n",
            "(25000, 20)\n",
            "[0 2 1 ... 0 0 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_without_label(parts, X_train_full,y_train_full):\n",
        "    \n",
        "        each_part_number=int(len(X_train_full)/parts)\n",
        "        list_x_train=[]\n",
        "        list_y_train=[]\n",
        "        \n",
        "        number_list=[]\n",
        "        number_list.append(0)\n",
        "        for x in range(1, parts+1):\n",
        "            number_list.append(each_part_number*x)\n",
        "        \n",
        "        \n",
        "        for x in range(0,parts):\n",
        "            data_x=X_train_full[number_list[x]:number_list[x+1]]\n",
        "            data_y=y_train_full[number_list[x]:number_list[x+1]]\n",
        "            list_x_train.append(data_x)\n",
        "            list_y_train.append(data_y)\n",
        "            \n",
        "        return list_x_train, list_y_train"
      ],
      "metadata": {
        "id": "6cI2W8qFwfm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data,y_data=divide_without_label(7, x_train, y_train)"
      ],
      "metadata": {
        "id": "xNx_BdoBwnSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for averaging\n",
        "def get_model():\n",
        "  model = keras.models.Sequential([\n",
        "          keras.layers.Embedding(voc_size,feature_vector_embedding, input_length=sentence_length),\n",
        "          keras.layers.GRU(30, return_sequences=True),\n",
        "          keras.layers.Dropout(0.5),\n",
        "          keras.layers.GRU(20, return_sequences=True),\n",
        "          keras.layers.GRU(10, return_sequences=True),\n",
        "          keras.layers.GRU(5),\n",
        "          keras.layers.Dense(3, activation=\"softmax\")\n",
        "      ])\n",
        "    \n",
        "  return model"
      ],
      "metadata": {
        "id": "EoUObm3owGkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_average(client_weights):\n",
        "    average_weight_list=[]\n",
        "    for index1 in range(len(client_weights[0])):\n",
        "        layer_weights=[]\n",
        "        for index2 in range(len(client_weights)):\n",
        "            weights=client_weights[index2][index1]\n",
        "            layer_weights.append(weights)\n",
        "        average_weight=np.mean(np.array([x for x in layer_weights]), axis=0)\n",
        "        average_weight_list.append(average_weight)\n",
        "    return average_weight_list"
      ],
      "metadata": {
        "id": "CJt-ILt2wH-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model=get_model()\n",
        "    weight=model.get_weights()\n",
        "    return weight"
      ],
      "metadata": {
        "id": "xOg6i2Sqy9rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(accuracy_list,weight,learning_rate):\n",
        "    model=get_model()  \n",
        "    model.set_weights(weight)\n",
        "    model.compile(loss='sparse_categorical_crossentropy',optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "    result=model.evaluate(x_test, y_test)\n",
        "            \n",
        "    if len(accuracy_list)==0:\n",
        "        accuracy_list.append(0)\n",
        "        if result[1] > accuracy_list[len(accuracy_list)-1]:\n",
        "            return True,result[1]\n",
        "        \n",
        "    elif result[1] > accuracy_list[len(accuracy_list)-1]:\n",
        "            return True,result[1]\n",
        "    else:\n",
        "        return False,result[1]"
      ],
      "metadata": {
        "id": "YieQxNkdw9SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_list_global=[]\n",
        "def train_server(training_rounds,epoch,batch,learning_rate):\n",
        "    \n",
        "    accuracy_list=[]\n",
        "    client_weight_for_sending=[]\n",
        "    \n",
        "    for index1 in range(1,training_rounds):\n",
        "        print('Training for round ', index1, 'started')\n",
        "        client_weights_tobe_averaged=[]\n",
        "        for index in range(len(y_data)):\n",
        "            print('-------Client-------', index)\n",
        "            if index1==1:\n",
        "                print('Sharing Initial Global Model with Random Weight Initialization')\n",
        "                initial_weight=create_model()\n",
        "                client=Client(x_data[index],y_data[index],epoch,learning_rate,initial_weight,batch,x_test, y_test)\n",
        "                weight=client.train()\n",
        "                client_weights_tobe_averaged.append(weight)\n",
        "            else:\n",
        "                client=Client(x_data[index],y_data[index],epoch,learning_rate,client_weight_for_sending[index1-2],batch,x_test, y_test)\n",
        "                weight=client.train()\n",
        "                client_weights_tobe_averaged.append(weight)\n",
        "    \n",
        "        #calculating the avearge weight from all the clients\n",
        "        client_average_weight=model_average(client_weights_tobe_averaged)\n",
        "        client_weight_for_sending.append(client_average_weight)\n",
        "\n",
        "\n",
        "        #validating the model with avearge weight\n",
        "        model=get_model()\n",
        "\n",
        "        model.set_weights(client_average_weight)\n",
        "        model.compile(loss='sparse_categorical_crossentropy',optimizer=keras.optimizers.SGD(lr=learning_rate),metrics=['accuracy'])\n",
        "        result=model.evaluate(x_test, y_test)\n",
        "        accuracy=result[1]\n",
        "        print('#######-----Acccuracy for round ', index1, 'is ', accuracy, ' ------########')\n",
        "        accuracy_list.append(accuracy)\n",
        "        accuracy_list_global.append(accuracy)\n",
        "        \n",
        "    return accuracy_list, client_weight_for_sending"
      ],
      "metadata": {
        "id": "RJS5bbHixCJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_main():\n",
        "    start=time.time()\n",
        "    training_accuracy,weights=train_server(10,5,32,0.01)\n",
        "    end=time.time()\n",
        "    print('TOTAL TIME = ', end-start)"
      ],
      "metadata": {
        "id": "1f3bUCBPxHjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "    train_main()"
      ],
      "metadata": {
        "id": "9mtq8kvJxIDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gGT6QRqT-4OG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}